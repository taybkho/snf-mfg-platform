[2025-12-17T11:30:56.491+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2025-12-17T11:30:56.521+0000] {taskinstance.py:2073} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: mfg_data_quality_monitoring_dag.dq_log_results scheduled__2025-12-16T05:30:00+00:00 [queued]>
[2025-12-17T11:30:56.529+0000] {taskinstance.py:2073} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: mfg_data_quality_monitoring_dag.dq_log_results scheduled__2025-12-16T05:30:00+00:00 [queued]>
[2025-12-17T11:30:56.530+0000] {taskinstance.py:2303} INFO - Starting attempt 1 of 2
[2025-12-17T11:30:56.544+0000] {taskinstance.py:2327} INFO - Executing <Task(PythonOperator): dq_log_results> on 2025-12-16 05:30:00+00:00
[2025-12-17T11:30:56.554+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'mfg_data_quality_monitoring_dag', 'dq_log_results', 'scheduled__2025-12-16T05:30:00+00:00', '--job-id', '26', '--raw', '--subdir', 'DAGS_FOLDER/mfg_data_quality_monitoring_dag.py', '--cfg-path', '/tmp/tmp96hj3d4q']
[2025-12-17T11:30:56.557+0000] {logging_mixin.py:188} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=3205) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-12-17T11:30:56.557+0000] {standard_task_runner.py:91} INFO - Job 26: Subtask dq_log_results
[2025-12-17T11:30:56.558+0000] {standard_task_runner.py:63} INFO - Started process 3208 to run task
[2025-12-17T11:30:56.626+0000] {task_command.py:426} INFO - Running <TaskInstance: mfg_data_quality_monitoring_dag.dq_log_results scheduled__2025-12-16T05:30:00+00:00 [running]> on host ada33a2b5ec7
[2025-12-17T11:30:56.729+0000] {taskinstance.py:2644} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='data-eng' AIRFLOW_CTX_DAG_ID='mfg_data_quality_monitoring_dag' AIRFLOW_CTX_TASK_ID='dq_log_results' AIRFLOW_CTX_EXECUTION_DATE='2025-12-16T05:30:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-12-16T05:30:00+00:00'
[2025-12-17T11:30:56.731+0000] {taskinstance.py:430} INFO - ::endgroup::
[2025-12-17T11:30:56.782+0000] {connection.py:521} INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.12.2, Platform: Linux-6.6.87.2-microsoft-standard-WSL2-x86_64-with-glibc2.36
[2025-12-17T11:30:56.783+0000] {connection.py:1464} INFO - Connecting to GLOBAL Snowflake domain
[2025-12-17T11:30:59.268+0000] {python.py:237} INFO - Done. Returned value was: None
[2025-12-17T11:30:59.269+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2025-12-17T11:30:59.282+0000] {taskinstance.py:1205} INFO - Marking task as SUCCESS. dag_id=mfg_data_quality_monitoring_dag, task_id=dq_log_results, execution_date=20251216T053000, start_date=20251217T113056, end_date=20251217T113059
[2025-12-17T11:30:59.310+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2025-12-17T11:30:59.331+0000] {taskinstance.py:3482} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-12-17T11:30:59.336+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2025-12-17T13:35:25.849+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2025-12-17T13:35:25.888+0000] {taskinstance.py:2073} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: mfg_data_quality_monitoring_dag.dq_log_results scheduled__2025-12-16T05:30:00+00:00 [queued]>
[2025-12-17T13:35:25.897+0000] {taskinstance.py:2073} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: mfg_data_quality_monitoring_dag.dq_log_results scheduled__2025-12-16T05:30:00+00:00 [queued]>
[2025-12-17T13:35:25.898+0000] {taskinstance.py:2303} INFO - Starting attempt 1 of 2
[2025-12-17T13:35:25.914+0000] {taskinstance.py:2327} INFO - Executing <Task(PythonOperator): dq_log_results> on 2025-12-16 05:30:00+00:00
[2025-12-17T13:35:25.924+0000] {logging_mixin.py:188} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=2723) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-12-17T13:35:25.924+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'mfg_data_quality_monitoring_dag', 'dq_log_results', 'scheduled__2025-12-16T05:30:00+00:00', '--job-id', '52', '--raw', '--subdir', 'DAGS_FOLDER/mfg_data_quality_monitoring_dag.py', '--cfg-path', '/tmp/tmproso3y9d']
[2025-12-17T13:35:25.927+0000] {standard_task_runner.py:63} INFO - Started process 2726 to run task
[2025-12-17T13:35:25.927+0000] {standard_task_runner.py:91} INFO - Job 52: Subtask dq_log_results
[2025-12-17T13:35:26.014+0000] {task_command.py:426} INFO - Running <TaskInstance: mfg_data_quality_monitoring_dag.dq_log_results scheduled__2025-12-16T05:30:00+00:00 [running]> on host 84fc30c39b31
[2025-12-17T13:35:26.121+0000] {taskinstance.py:2644} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='data-eng' AIRFLOW_CTX_DAG_ID='mfg_data_quality_monitoring_dag' AIRFLOW_CTX_TASK_ID='dq_log_results' AIRFLOW_CTX_EXECUTION_DATE='2025-12-16T05:30:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-12-16T05:30:00+00:00'
[2025-12-17T13:35:26.122+0000] {taskinstance.py:430} INFO - ::endgroup::
[2025-12-17T13:35:26.149+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2025-12-17T13:35:26.150+0000] {taskinstance.py:2890} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 460, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 400, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 235, in execute
    return_value = self.execute_callable()
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 252, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/mfg_data_quality_monitoring_dag.py", line 182, in dq_log_results
    payload = ti.xcom_pull(task_ids=task_id)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3259, in xcom_pull
    return XCom.deserialize_value(first)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/xcom.py", line 707, in deserialize_value
    return BaseXCom._deserialize_value(result, False)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/xcom.py", line 702, in _deserialize_value
    return json.loads(result.value.decode("UTF-8"), cls=XComDecoder, object_hook=object_hook)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/json/__init__.py", line 359, in loads
    return cls(**kw).decode(s)
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/json/decoder.py", line 353, in raw_decode
    obj, end = self.scan_once(s, idx)
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/json.py", line 117, in object_hook
    return deserialize(dct)
           ^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/serialization/serde.py", line 254, in deserialize
    raise ImportError(
ImportError: unusual_prefix_ac3778cd2311aa0fdf4029b8aedfef7b89091164_mfg_data_quality_monitoring_dag.CheckResult was not found in allow list for deserialization imports. To allow it, add it to allowed_deserialization_classes in the configuration
[2025-12-17T13:35:26.170+0000] {taskinstance.py:1205} INFO - Marking task as UP_FOR_RETRY. dag_id=mfg_data_quality_monitoring_dag, task_id=dq_log_results, execution_date=20251216T053000, start_date=20251217T133525, end_date=20251217T133526
[2025-12-17T13:35:26.182+0000] {standard_task_runner.py:110} ERROR - Failed to execute job 52 for task dq_log_results (unusual_prefix_ac3778cd2311aa0fdf4029b8aedfef7b89091164_mfg_data_quality_monitoring_dag.CheckResult was not found in allow list for deserialization imports. To allow it, add it to allowed_deserialization_classes in the configuration; 2726)
[2025-12-17T13:35:26.222+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 1
[2025-12-17T13:35:26.241+0000] {taskinstance.py:3482} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-12-17T13:35:26.246+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2025-12-17T13:45:06.600+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2025-12-17T13:45:06.651+0000] {taskinstance.py:2073} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: mfg_data_quality_monitoring_dag.dq_log_results scheduled__2025-12-16T05:30:00+00:00 [queued]>
[2025-12-17T13:45:06.664+0000] {taskinstance.py:2073} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: mfg_data_quality_monitoring_dag.dq_log_results scheduled__2025-12-16T05:30:00+00:00 [queued]>
[2025-12-17T13:45:06.665+0000] {taskinstance.py:2303} INFO - Starting attempt 1 of 2
[2025-12-17T13:45:06.683+0000] {taskinstance.py:2327} INFO - Executing <Task(PythonOperator): dq_log_results> on 2025-12-16 05:30:00+00:00
[2025-12-17T13:45:06.695+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'mfg_data_quality_monitoring_dag', 'dq_log_results', 'scheduled__2025-12-16T05:30:00+00:00', '--job-id', '7', '--raw', '--subdir', 'DAGS_FOLDER/mfg_data_quality_monitoring_dag.py', '--cfg-path', '/tmp/tmpeeg0p4hf']
[2025-12-17T13:45:06.699+0000] {standard_task_runner.py:91} INFO - Job 7: Subtask dq_log_results
[2025-12-17T13:45:06.700+0000] {logging_mixin.py:188} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=245) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-12-17T13:45:06.701+0000] {standard_task_runner.py:63} INFO - Started process 249 to run task
[2025-12-17T13:45:06.795+0000] {task_command.py:426} INFO - Running <TaskInstance: mfg_data_quality_monitoring_dag.dq_log_results scheduled__2025-12-16T05:30:00+00:00 [running]> on host 8717822a88d5
[2025-12-17T13:45:06.929+0000] {taskinstance.py:2644} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='data-eng' AIRFLOW_CTX_DAG_ID='mfg_data_quality_monitoring_dag' AIRFLOW_CTX_TASK_ID='dq_log_results' AIRFLOW_CTX_EXECUTION_DATE='2025-12-16T05:30:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-12-16T05:30:00+00:00'
[2025-12-17T13:45:06.931+0000] {taskinstance.py:430} INFO - ::endgroup::
[2025-12-17T13:45:06.967+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2025-12-17T13:45:06.968+0000] {taskinstance.py:2890} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 460, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 400, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 235, in execute
    return_value = self.execute_callable()
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 252, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/mfg_data_quality_monitoring_dag.py", line 182, in dq_log_results
    payload = ti.xcom_pull(task_ids=task_id)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3259, in xcom_pull
    return XCom.deserialize_value(first)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/xcom.py", line 707, in deserialize_value
    return BaseXCom._deserialize_value(result, False)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/xcom.py", line 702, in _deserialize_value
    return json.loads(result.value.decode("UTF-8"), cls=XComDecoder, object_hook=object_hook)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/json/__init__.py", line 359, in loads
    return cls(**kw).decode(s)
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/json/decoder.py", line 353, in raw_decode
    obj, end = self.scan_once(s, idx)
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/json.py", line 117, in object_hook
    return deserialize(dct)
           ^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/serialization/serde.py", line 254, in deserialize
    raise ImportError(
ImportError: unusual_prefix_ac3778cd2311aa0fdf4029b8aedfef7b89091164_mfg_data_quality_monitoring_dag.CheckResult was not found in allow list for deserialization imports. To allow it, add it to allowed_deserialization_classes in the configuration
[2025-12-17T13:45:06.992+0000] {taskinstance.py:1205} INFO - Marking task as UP_FOR_RETRY. dag_id=mfg_data_quality_monitoring_dag, task_id=dq_log_results, execution_date=20251216T053000, start_date=20251217T134506, end_date=20251217T134506
[2025-12-17T13:45:07.007+0000] {standard_task_runner.py:110} ERROR - Failed to execute job 7 for task dq_log_results (unusual_prefix_ac3778cd2311aa0fdf4029b8aedfef7b89091164_mfg_data_quality_monitoring_dag.CheckResult was not found in allow list for deserialization imports. To allow it, add it to allowed_deserialization_classes in the configuration; 249)
[2025-12-17T13:45:07.037+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 1
[2025-12-17T13:45:07.062+0000] {taskinstance.py:3482} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-12-17T13:45:07.066+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2025-12-17T18:25:37.290+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2025-12-17T18:25:37.320+0000] {taskinstance.py:2073} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: mfg_data_quality_monitoring_dag.dq_log_results scheduled__2025-12-16T05:30:00+00:00 [queued]>
[2025-12-17T18:25:37.328+0000] {taskinstance.py:2073} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: mfg_data_quality_monitoring_dag.dq_log_results scheduled__2025-12-16T05:30:00+00:00 [queued]>
[2025-12-17T18:25:37.329+0000] {taskinstance.py:2303} INFO - Starting attempt 1 of 2
[2025-12-17T18:25:37.342+0000] {taskinstance.py:2327} INFO - Executing <Task(PythonOperator): dq_log_results> on 2025-12-16 05:30:00+00:00
[2025-12-17T18:25:37.351+0000] {logging_mixin.py:188} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=2359) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-12-17T18:25:37.352+0000] {standard_task_runner.py:63} INFO - Started process 2362 to run task
[2025-12-17T18:25:37.351+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'mfg_data_quality_monitoring_dag', 'dq_log_results', 'scheduled__2025-12-16T05:30:00+00:00', '--job-id', '51', '--raw', '--subdir', 'DAGS_FOLDER/mfg_data_quality_monitoring_dag.py', '--cfg-path', '/tmp/tmp4657foha']
[2025-12-17T18:25:37.353+0000] {standard_task_runner.py:91} INFO - Job 51: Subtask dq_log_results
[2025-12-17T18:25:37.418+0000] {task_command.py:426} INFO - Running <TaskInstance: mfg_data_quality_monitoring_dag.dq_log_results scheduled__2025-12-16T05:30:00+00:00 [running]> on host 8717822a88d5
[2025-12-17T18:25:37.520+0000] {taskinstance.py:2644} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='data-eng' AIRFLOW_CTX_DAG_ID='mfg_data_quality_monitoring_dag' AIRFLOW_CTX_TASK_ID='dq_log_results' AIRFLOW_CTX_EXECUTION_DATE='2025-12-16T05:30:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-12-16T05:30:00+00:00'
[2025-12-17T18:25:37.522+0000] {taskinstance.py:430} INFO - ::endgroup::
[2025-12-17T18:25:37.571+0000] {connection.py:414} INFO - Snowflake Connector for Python Version: 3.12.0, Python Version: 3.12.2, Platform: Linux-6.6.87.2-microsoft-standard-WSL2-x86_64-with-glibc2.36
[2025-12-17T18:25:37.572+0000] {connection.py:1187} INFO - Connecting to GLOBAL Snowflake domain
[2025-12-17T18:25:37.573+0000] {connection.py:1268} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2025-12-17T18:25:38.920+0000] {cursor.py:1156} INFO - Number of results in first chunk: 1
[2025-12-17T18:25:39.195+0000] {cursor.py:1156} INFO - Number of results in first chunk: 1
[2025-12-17T18:25:39.483+0000] {connection.py:779} INFO - closed
[2025-12-17T18:25:39.713+0000] {connection.py:785} INFO - No async queries seem to be running, deleting session
[2025-12-17T18:25:39.966+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2025-12-17T18:25:39.968+0000] {taskinstance.py:2890} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 460, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 400, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 235, in execute
    return_value = self.execute_callable()
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 252, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/mfg_data_quality_monitoring_dag.py", line 253, in dq_log_results
    cur.execute(
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/cursor.py", line 1087, in execute
    Error.errorhandler_wrapper(self.connection, self, error_class, errvalue)
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/errors.py", line 290, in errorhandler_wrapper
    handed_over = Error.hand_to_other_handler(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/errors.py", line 345, in hand_to_other_handler
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/errors.py", line 221, in default_errorhandler
    raise error_class(
snowflake.connector.errors.ProgrammingError: 000904 (42000): 01c11db1-0107-4d9d-0013-40ff00177172: SQL compilation error: error line 2 at position 29
invalid identifier 'SEVERITY'
[2025-12-17T18:25:39.981+0000] {taskinstance.py:1205} INFO - Marking task as UP_FOR_RETRY. dag_id=mfg_data_quality_monitoring_dag, task_id=dq_log_results, execution_date=20251216T053000, start_date=20251217T182537, end_date=20251217T182539
[2025-12-17T18:25:39.993+0000] {standard_task_runner.py:110} ERROR - Failed to execute job 51 for task dq_log_results (000904 (42000): 01c11db1-0107-4d9d-0013-40ff00177172: SQL compilation error: error line 2 at position 29
invalid identifier 'SEVERITY'; 2362)
[2025-12-17T18:25:40.032+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 1
[2025-12-17T18:25:40.050+0000] {taskinstance.py:3482} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-12-17T18:25:40.055+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
