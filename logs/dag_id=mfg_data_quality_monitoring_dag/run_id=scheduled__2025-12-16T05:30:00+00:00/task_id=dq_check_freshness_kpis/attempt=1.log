[2025-12-17T11:25:47.145+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2025-12-17T11:25:47.190+0000] {taskinstance.py:2073} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: mfg_data_quality_monitoring_dag.dq_check_freshness_kpis scheduled__2025-12-16T05:30:00+00:00 [queued]>
[2025-12-17T11:25:47.200+0000] {taskinstance.py:2073} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: mfg_data_quality_monitoring_dag.dq_check_freshness_kpis scheduled__2025-12-16T05:30:00+00:00 [queued]>
[2025-12-17T11:25:47.201+0000] {taskinstance.py:2303} INFO - Starting attempt 1 of 2
[2025-12-17T11:25:47.220+0000] {taskinstance.py:2327} INFO - Executing <Task(PythonOperator): dq_check_freshness_kpis> on 2025-12-16 05:30:00+00:00
[2025-12-17T11:25:47.238+0000] {logging_mixin.py:188} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=2668) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-12-17T11:25:47.232+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'mfg_data_quality_monitoring_dag', 'dq_check_freshness_kpis', 'scheduled__2025-12-16T05:30:00+00:00', '--job-id', '17', '--raw', '--subdir', 'DAGS_FOLDER/mfg_data_quality_monitoring_dag.py', '--cfg-path', '/tmp/tmpw0fek42z']
[2025-12-17T11:25:47.239+0000] {standard_task_runner.py:63} INFO - Started process 2690 to run task
[2025-12-17T11:25:47.245+0000] {standard_task_runner.py:91} INFO - Job 17: Subtask dq_check_freshness_kpis
[2025-12-17T11:25:47.345+0000] {task_command.py:426} INFO - Running <TaskInstance: mfg_data_quality_monitoring_dag.dq_check_freshness_kpis scheduled__2025-12-16T05:30:00+00:00 [running]> on host ada33a2b5ec7
[2025-12-17T11:25:47.502+0000] {taskinstance.py:2644} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='data-eng' AIRFLOW_CTX_DAG_ID='mfg_data_quality_monitoring_dag' AIRFLOW_CTX_TASK_ID='dq_check_freshness_kpis' AIRFLOW_CTX_EXECUTION_DATE='2025-12-16T05:30:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-12-16T05:30:00+00:00'
[2025-12-17T11:25:47.505+0000] {taskinstance.py:430} INFO - ::endgroup::
[2025-12-17T11:25:47.524+0000] {connection.py:521} INFO - Snowflake Connector for Python Version: 3.18.0, Python Version: 3.12.2, Platform: Linux-6.6.87.2-microsoft-standard-WSL2-x86_64-with-glibc2.36
[2025-12-17T11:25:47.526+0000] {connection.py:1464} INFO - Connecting to GLOBAL Snowflake domain
[2025-12-17T11:25:49.995+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2025-12-17T11:25:49.996+0000] {taskinstance.py:2890} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 460, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 400, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 235, in execute
    return_value = self.execute_callable()
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 252, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/mfg_data_quality_monitoring_dag.py", line 144, in dq_check_freshness_kpis
    max_date = _fetch_one(cur, f"SELECT MAX(CALENDAR_DATE) FROM {db}.MARTS.MFG_PLANT_DAILY_KPIS")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/mfg_data_quality_monitoring_dag.py", line 74, in _fetch_one
    cur.execute(sql, params or ())
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/cursor.py", line 1134, in execute
    Error.errorhandler_wrapper(self.connection, self, error_class, errvalue)
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/errors.py", line 286, in errorhandler_wrapper
    handed_over = Error.hand_to_other_handler(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/errors.py", line 341, in hand_to_other_handler
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/errors.py", line 217, in default_errorhandler
    raise error_class(
snowflake.connector.errors.ProgrammingError: 002003 (42S02): 01c11c0d-0107-48e8-0013-40ff00170342: SQL compilation error:
Object 'MFG_ACCELERATOR.MARTS.MFG_PLANT_DAILY_KPIS' does not exist or not authorized.
[2025-12-17T11:25:50.015+0000] {taskinstance.py:1205} INFO - Marking task as UP_FOR_RETRY. dag_id=mfg_data_quality_monitoring_dag, task_id=dq_check_freshness_kpis, execution_date=20251216T053000, start_date=20251217T112547, end_date=20251217T112550
[2025-12-17T11:25:50.030+0000] {standard_task_runner.py:110} ERROR - Failed to execute job 17 for task dq_check_freshness_kpis (002003 (42S02): 01c11c0d-0107-48e8-0013-40ff00170342: SQL compilation error:
Object 'MFG_ACCELERATOR.MARTS.MFG_PLANT_DAILY_KPIS' does not exist or not authorized.; 2690)
[2025-12-17T11:25:50.076+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 1
[2025-12-17T11:25:50.110+0000] {taskinstance.py:3482} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-12-17T11:25:50.116+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2025-12-17T13:04:52.828+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2025-12-17T13:04:52.887+0000] {taskinstance.py:2073} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: mfg_data_quality_monitoring_dag.dq_check_freshness_kpis scheduled__2025-12-16T05:30:00+00:00 [queued]>
[2025-12-17T13:04:52.900+0000] {taskinstance.py:2073} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: mfg_data_quality_monitoring_dag.dq_check_freshness_kpis scheduled__2025-12-16T05:30:00+00:00 [queued]>
[2025-12-17T13:04:52.904+0000] {taskinstance.py:2303} INFO - Starting attempt 1 of 2
[2025-12-17T13:04:52.926+0000] {taskinstance.py:2327} INFO - Executing <Task(PythonOperator): dq_check_freshness_kpis> on 2025-12-16 05:30:00+00:00
[2025-12-17T13:04:52.946+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'mfg_data_quality_monitoring_dag', 'dq_check_freshness_kpis', 'scheduled__2025-12-16T05:30:00+00:00', '--job-id', '9', '--raw', '--subdir', 'DAGS_FOLDER/mfg_data_quality_monitoring_dag.py', '--cfg-path', '/tmp/tmpj0mgzh2r']
[2025-12-17T13:04:52.954+0000] {logging_mixin.py:188} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=754) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-12-17T13:04:52.955+0000] {standard_task_runner.py:91} INFO - Job 9: Subtask dq_check_freshness_kpis
[2025-12-17T13:04:52.956+0000] {standard_task_runner.py:63} INFO - Started process 771 to run task
[2025-12-17T13:04:53.092+0000] {task_command.py:426} INFO - Running <TaskInstance: mfg_data_quality_monitoring_dag.dq_check_freshness_kpis scheduled__2025-12-16T05:30:00+00:00 [running]> on host 84fc30c39b31
[2025-12-17T13:04:53.290+0000] {taskinstance.py:2644} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='data-eng' AIRFLOW_CTX_DAG_ID='mfg_data_quality_monitoring_dag' AIRFLOW_CTX_TASK_ID='dq_check_freshness_kpis' AIRFLOW_CTX_EXECUTION_DATE='2025-12-16T05:30:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-12-16T05:30:00+00:00'
[2025-12-17T13:04:53.292+0000] {taskinstance.py:430} INFO - ::endgroup::
[2025-12-17T13:04:53.321+0000] {connection.py:414} INFO - Snowflake Connector for Python Version: 3.12.0, Python Version: 3.12.2, Platform: Linux-6.6.87.2-microsoft-standard-WSL2-x86_64-with-glibc2.36
[2025-12-17T13:04:53.324+0000] {connection.py:1187} INFO - Connecting to GLOBAL Snowflake domain
[2025-12-17T13:04:53.325+0000] {connection.py:1268} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2025-12-17T13:04:55.017+0000] {connection.py:779} INFO - closed
[2025-12-17T13:04:55.240+0000] {connection.py:785} INFO - No async queries seem to be running, deleting session
[2025-12-17T13:04:55.581+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2025-12-17T13:04:55.582+0000] {taskinstance.py:2890} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 460, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 400, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 235, in execute
    return_value = self.execute_callable()
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 252, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/mfg_data_quality_monitoring_dag.py", line 144, in dq_check_freshness_kpis
    max_date = _fetch_one(cur, f"SELECT MAX(CALENDAR_DATE) FROM {db}.MARTS.MFG_PLANT_DAILY_KPIS")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/mfg_data_quality_monitoring_dag.py", line 74, in _fetch_one
    cur.execute(sql, params or ())
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/cursor.py", line 1087, in execute
    Error.errorhandler_wrapper(self.connection, self, error_class, errvalue)
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/errors.py", line 290, in errorhandler_wrapper
    handed_over = Error.hand_to_other_handler(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/errors.py", line 345, in hand_to_other_handler
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/errors.py", line 221, in default_errorhandler
    raise error_class(
snowflake.connector.errors.ProgrammingError: 002003 (42S02): 01c11c70-0107-48e8-0013-40ff00170802: SQL compilation error:
Object 'MFG_ACCELERATOR.MARTS.MFG_PLANT_DAILY_KPIS' does not exist or not authorized.
[2025-12-17T13:04:55.597+0000] {taskinstance.py:1205} INFO - Marking task as UP_FOR_RETRY. dag_id=mfg_data_quality_monitoring_dag, task_id=dq_check_freshness_kpis, execution_date=20251216T053000, start_date=20251217T130452, end_date=20251217T130455
[2025-12-17T13:04:55.613+0000] {standard_task_runner.py:110} ERROR - Failed to execute job 9 for task dq_check_freshness_kpis (002003 (42S02): 01c11c70-0107-48e8-0013-40ff00170802: SQL compilation error:
Object 'MFG_ACCELERATOR.MARTS.MFG_PLANT_DAILY_KPIS' does not exist or not authorized.; 771)
[2025-12-17T13:04:55.637+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 1
[2025-12-17T13:04:55.660+0000] {taskinstance.py:3482} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-12-17T13:04:55.666+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2025-12-17T13:14:01.229+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2025-12-17T13:14:01.276+0000] {taskinstance.py:2073} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: mfg_data_quality_monitoring_dag.dq_check_freshness_kpis scheduled__2025-12-16T05:30:00+00:00 [queued]>
[2025-12-17T13:14:01.287+0000] {taskinstance.py:2073} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: mfg_data_quality_monitoring_dag.dq_check_freshness_kpis scheduled__2025-12-16T05:30:00+00:00 [queued]>
[2025-12-17T13:14:01.288+0000] {taskinstance.py:2303} INFO - Starting attempt 1 of 2
[2025-12-17T13:14:01.304+0000] {taskinstance.py:2327} INFO - Executing <Task(PythonOperator): dq_check_freshness_kpis> on 2025-12-16 05:30:00+00:00
[2025-12-17T13:14:01.316+0000] {logging_mixin.py:188} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=1630) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-12-17T13:14:01.315+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'mfg_data_quality_monitoring_dag', 'dq_check_freshness_kpis', 'scheduled__2025-12-16T05:30:00+00:00', '--job-id', '36', '--raw', '--subdir', 'DAGS_FOLDER/mfg_data_quality_monitoring_dag.py', '--cfg-path', '/tmp/tmpzvkugswm']
[2025-12-17T13:14:01.318+0000] {standard_task_runner.py:63} INFO - Started process 1639 to run task
[2025-12-17T13:14:01.319+0000] {standard_task_runner.py:91} INFO - Job 36: Subtask dq_check_freshness_kpis
[2025-12-17T13:14:01.425+0000] {task_command.py:426} INFO - Running <TaskInstance: mfg_data_quality_monitoring_dag.dq_check_freshness_kpis scheduled__2025-12-16T05:30:00+00:00 [running]> on host 84fc30c39b31
[2025-12-17T13:14:01.582+0000] {taskinstance.py:2644} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='data-eng' AIRFLOW_CTX_DAG_ID='mfg_data_quality_monitoring_dag' AIRFLOW_CTX_TASK_ID='dq_check_freshness_kpis' AIRFLOW_CTX_EXECUTION_DATE='2025-12-16T05:30:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-12-16T05:30:00+00:00'
[2025-12-17T13:14:01.584+0000] {taskinstance.py:430} INFO - ::endgroup::
[2025-12-17T13:14:01.607+0000] {connection.py:414} INFO - Snowflake Connector for Python Version: 3.12.0, Python Version: 3.12.2, Platform: Linux-6.6.87.2-microsoft-standard-WSL2-x86_64-with-glibc2.36
[2025-12-17T13:14:01.609+0000] {connection.py:1187} INFO - Connecting to GLOBAL Snowflake domain
[2025-12-17T13:14:01.614+0000] {connection.py:1268} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2025-12-17T13:14:03.369+0000] {connection.py:779} INFO - closed
[2025-12-17T13:14:03.565+0000] {connection.py:785} INFO - No async queries seem to be running, deleting session
[2025-12-17T13:14:03.802+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2025-12-17T13:14:03.804+0000] {taskinstance.py:2890} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 460, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 400, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 235, in execute
    return_value = self.execute_callable()
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 252, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/mfg_data_quality_monitoring_dag.py", line 144, in dq_check_freshness_kpis
    max_date = _fetch_one(cur, f"SELECT MAX(CALENDAR_DATE) FROM {db}.MARTS.MFG_PLANT_DAILY_KPIS")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/mfg_data_quality_monitoring_dag.py", line 74, in _fetch_one
    cur.execute(sql, params or ())
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/cursor.py", line 1087, in execute
    Error.errorhandler_wrapper(self.connection, self, error_class, errvalue)
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/errors.py", line 290, in errorhandler_wrapper
    handed_over = Error.hand_to_other_handler(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/errors.py", line 345, in hand_to_other_handler
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/errors.py", line 221, in default_errorhandler
    raise error_class(
snowflake.connector.errors.ProgrammingError: 002003 (42S02): 01c11c7a-0107-4c39-0013-40ff00171a22: SQL compilation error:
Object 'MFG_ACCELERATOR.MARTS.MFG_PLANT_DAILY_KPIS' does not exist or not authorized.
[2025-12-17T13:14:03.827+0000] {taskinstance.py:1205} INFO - Marking task as UP_FOR_RETRY. dag_id=mfg_data_quality_monitoring_dag, task_id=dq_check_freshness_kpis, execution_date=20251216T053000, start_date=20251217T131401, end_date=20251217T131403
[2025-12-17T13:14:03.848+0000] {standard_task_runner.py:110} ERROR - Failed to execute job 36 for task dq_check_freshness_kpis (002003 (42S02): 01c11c7a-0107-4c39-0013-40ff00171a22: SQL compilation error:
Object 'MFG_ACCELERATOR.MARTS.MFG_PLANT_DAILY_KPIS' does not exist or not authorized.; 1639)
[2025-12-17T13:14:03.872+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 1
[2025-12-17T13:14:03.918+0000] {taskinstance.py:3482} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-12-17T13:14:03.924+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2025-12-17T13:19:17.027+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2025-12-17T13:19:17.071+0000] {taskinstance.py:2073} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: mfg_data_quality_monitoring_dag.dq_check_freshness_kpis scheduled__2025-12-16T05:30:00+00:00 [queued]>
[2025-12-17T13:19:17.081+0000] {taskinstance.py:2073} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: mfg_data_quality_monitoring_dag.dq_check_freshness_kpis scheduled__2025-12-16T05:30:00+00:00 [queued]>
[2025-12-17T13:19:17.082+0000] {taskinstance.py:2303} INFO - Starting attempt 1 of 2
[2025-12-17T13:19:17.099+0000] {taskinstance.py:2327} INFO - Executing <Task(PythonOperator): dq_check_freshness_kpis> on 2025-12-16 05:30:00+00:00
[2025-12-17T13:19:17.113+0000] {logging_mixin.py:188} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=1900) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-12-17T13:19:17.115+0000] {standard_task_runner.py:63} INFO - Started process 1908 to run task
[2025-12-17T13:19:17.114+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'mfg_data_quality_monitoring_dag', 'dq_check_freshness_kpis', 'scheduled__2025-12-16T05:30:00+00:00', '--job-id', '40', '--raw', '--subdir', 'DAGS_FOLDER/mfg_data_quality_monitoring_dag.py', '--cfg-path', '/tmp/tmpsgqutou0']
[2025-12-17T13:19:17.120+0000] {standard_task_runner.py:91} INFO - Job 40: Subtask dq_check_freshness_kpis
[2025-12-17T13:19:17.232+0000] {task_command.py:426} INFO - Running <TaskInstance: mfg_data_quality_monitoring_dag.dq_check_freshness_kpis scheduled__2025-12-16T05:30:00+00:00 [running]> on host 84fc30c39b31
[2025-12-17T13:19:17.387+0000] {taskinstance.py:2644} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='data-eng' AIRFLOW_CTX_DAG_ID='mfg_data_quality_monitoring_dag' AIRFLOW_CTX_TASK_ID='dq_check_freshness_kpis' AIRFLOW_CTX_EXECUTION_DATE='2025-12-16T05:30:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-12-16T05:30:00+00:00'
[2025-12-17T13:19:17.389+0000] {taskinstance.py:430} INFO - ::endgroup::
[2025-12-17T13:19:17.413+0000] {connection.py:414} INFO - Snowflake Connector for Python Version: 3.12.0, Python Version: 3.12.2, Platform: Linux-6.6.87.2-microsoft-standard-WSL2-x86_64-with-glibc2.36
[2025-12-17T13:19:17.414+0000] {connection.py:1187} INFO - Connecting to GLOBAL Snowflake domain
[2025-12-17T13:19:17.415+0000] {connection.py:1268} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2025-12-17T13:19:19.484+0000] {connection.py:779} INFO - closed
[2025-12-17T13:19:19.678+0000] {connection.py:785} INFO - No async queries seem to be running, deleting session
[2025-12-17T13:19:19.897+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2025-12-17T13:19:19.898+0000] {taskinstance.py:2890} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 460, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 400, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 235, in execute
    return_value = self.execute_callable()
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 252, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/mfg_data_quality_monitoring_dag.py", line 144, in dq_check_freshness_kpis
    max_date = _fetch_one(cur, f"SELECT MAX(CALENDAR_DATE) FROM {db}.MARTS.MFG_PLANT_DAILY_KPIS")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/mfg_data_quality_monitoring_dag.py", line 74, in _fetch_one
    cur.execute(sql, params or ())
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/cursor.py", line 1087, in execute
    Error.errorhandler_wrapper(self.connection, self, error_class, errvalue)
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/errors.py", line 290, in errorhandler_wrapper
    handed_over = Error.hand_to_other_handler(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/errors.py", line 345, in hand_to_other_handler
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/errors.py", line 221, in default_errorhandler
    raise error_class(
snowflake.connector.errors.ProgrammingError: 002003 (42S02): 01c11c7f-0107-4c39-0013-40ff00171ae2: SQL compilation error:
Object 'MFG_ACCELERATOR.MARTS.MFG_PLANT_DAILY_KPIS' does not exist or not authorized.
[2025-12-17T13:19:19.915+0000] {taskinstance.py:1205} INFO - Marking task as UP_FOR_RETRY. dag_id=mfg_data_quality_monitoring_dag, task_id=dq_check_freshness_kpis, execution_date=20251216T053000, start_date=20251217T131917, end_date=20251217T131919
[2025-12-17T13:19:19.928+0000] {standard_task_runner.py:110} ERROR - Failed to execute job 40 for task dq_check_freshness_kpis (002003 (42S02): 01c11c7f-0107-4c39-0013-40ff00171ae2: SQL compilation error:
Object 'MFG_ACCELERATOR.MARTS.MFG_PLANT_DAILY_KPIS' does not exist or not authorized.; 1908)
[2025-12-17T13:19:19.952+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 1
[2025-12-17T13:19:19.986+0000] {taskinstance.py:3482} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-12-17T13:19:19.994+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2025-12-17T13:30:16.725+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2025-12-17T13:30:16.775+0000] {taskinstance.py:2073} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: mfg_data_quality_monitoring_dag.dq_check_freshness_kpis scheduled__2025-12-16T05:30:00+00:00 [queued]>
[2025-12-17T13:30:16.789+0000] {taskinstance.py:2073} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: mfg_data_quality_monitoring_dag.dq_check_freshness_kpis scheduled__2025-12-16T05:30:00+00:00 [queued]>
[2025-12-17T13:30:16.790+0000] {taskinstance.py:2303} INFO - Starting attempt 1 of 2
[2025-12-17T13:30:16.811+0000] {taskinstance.py:2327} INFO - Executing <Task(PythonOperator): dq_check_freshness_kpis> on 2025-12-16 05:30:00+00:00
[2025-12-17T13:30:16.835+0000] {logging_mixin.py:188} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=2442) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-12-17T13:30:16.828+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'mfg_data_quality_monitoring_dag', 'dq_check_freshness_kpis', 'scheduled__2025-12-16T05:30:00+00:00', '--job-id', '50', '--raw', '--subdir', 'DAGS_FOLDER/mfg_data_quality_monitoring_dag.py', '--cfg-path', '/tmp/tmptaqtzfk9']
[2025-12-17T13:30:16.838+0000] {standard_task_runner.py:63} INFO - Started process 2453 to run task
[2025-12-17T13:30:16.838+0000] {standard_task_runner.py:91} INFO - Job 50: Subtask dq_check_freshness_kpis
[2025-12-17T13:30:16.969+0000] {task_command.py:426} INFO - Running <TaskInstance: mfg_data_quality_monitoring_dag.dq_check_freshness_kpis scheduled__2025-12-16T05:30:00+00:00 [running]> on host 84fc30c39b31
[2025-12-17T13:30:17.131+0000] {taskinstance.py:2644} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='data-eng' AIRFLOW_CTX_DAG_ID='mfg_data_quality_monitoring_dag' AIRFLOW_CTX_TASK_ID='dq_check_freshness_kpis' AIRFLOW_CTX_EXECUTION_DATE='2025-12-16T05:30:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-12-16T05:30:00+00:00'
[2025-12-17T13:30:17.133+0000] {taskinstance.py:430} INFO - ::endgroup::
[2025-12-17T13:30:17.153+0000] {connection.py:414} INFO - Snowflake Connector for Python Version: 3.12.0, Python Version: 3.12.2, Platform: Linux-6.6.87.2-microsoft-standard-WSL2-x86_64-with-glibc2.36
[2025-12-17T13:30:17.154+0000] {connection.py:1187} INFO - Connecting to GLOBAL Snowflake domain
[2025-12-17T13:30:17.155+0000] {connection.py:1268} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2025-12-17T13:30:19.178+0000] {connection.py:779} INFO - closed
[2025-12-17T13:30:19.406+0000] {connection.py:785} INFO - No async queries seem to be running, deleting session
[2025-12-17T13:30:19.684+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2025-12-17T13:30:19.685+0000] {taskinstance.py:2890} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 460, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 400, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 235, in execute
    return_value = self.execute_callable()
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 252, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/mfg_data_quality_monitoring_dag.py", line 144, in dq_check_freshness_kpis
    max_date = _fetch_one(cur, f"SELECT MAX(CALENDAR_DATE) FROM {db}.MARTS.MFG_PLANT_DAILY_KPIS")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/mfg_data_quality_monitoring_dag.py", line 74, in _fetch_one
    cur.execute(sql, params or ())
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/cursor.py", line 1087, in execute
    Error.errorhandler_wrapper(self.connection, self, error_class, errvalue)
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/errors.py", line 290, in errorhandler_wrapper
    handed_over = Error.hand_to_other_handler(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/errors.py", line 345, in hand_to_other_handler
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/errors.py", line 221, in default_errorhandler
    raise error_class(
snowflake.connector.errors.ProgrammingError: 002003 (42S02): 01c11c8a-0107-4d17-0013-40ff001741e2: SQL compilation error:
Object 'MFG_ACCELERATOR.MARTS.MFG_PLANT_DAILY_KPIS' does not exist or not authorized.
[2025-12-17T13:30:19.703+0000] {taskinstance.py:1205} INFO - Marking task as UP_FOR_RETRY. dag_id=mfg_data_quality_monitoring_dag, task_id=dq_check_freshness_kpis, execution_date=20251216T053000, start_date=20251217T133016, end_date=20251217T133019
[2025-12-17T13:30:19.720+0000] {standard_task_runner.py:110} ERROR - Failed to execute job 50 for task dq_check_freshness_kpis (002003 (42S02): 01c11c8a-0107-4d17-0013-40ff001741e2: SQL compilation error:
Object 'MFG_ACCELERATOR.MARTS.MFG_PLANT_DAILY_KPIS' does not exist or not authorized.; 2453)
[2025-12-17T13:30:19.754+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 1
[2025-12-17T13:30:19.788+0000] {taskinstance.py:3482} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-12-17T13:30:19.793+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2025-12-17T13:44:59.236+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2025-12-17T13:44:59.294+0000] {taskinstance.py:2073} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: mfg_data_quality_monitoring_dag.dq_check_freshness_kpis scheduled__2025-12-16T05:30:00+00:00 [queued]>
[2025-12-17T13:44:59.309+0000] {taskinstance.py:2073} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: mfg_data_quality_monitoring_dag.dq_check_freshness_kpis scheduled__2025-12-16T05:30:00+00:00 [queued]>
[2025-12-17T13:44:59.310+0000] {taskinstance.py:2303} INFO - Starting attempt 1 of 2
[2025-12-17T13:44:59.335+0000] {taskinstance.py:2327} INFO - Executing <Task(PythonOperator): dq_check_freshness_kpis> on 2025-12-16 05:30:00+00:00
[2025-12-17T13:44:59.352+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'mfg_data_quality_monitoring_dag', 'dq_check_freshness_kpis', 'scheduled__2025-12-16T05:30:00+00:00', '--job-id', '6', '--raw', '--subdir', 'DAGS_FOLDER/mfg_data_quality_monitoring_dag.py', '--cfg-path', '/tmp/tmpw7buk0m3']
[2025-12-17T13:44:59.358+0000] {standard_task_runner.py:91} INFO - Job 6: Subtask dq_check_freshness_kpis
[2025-12-17T13:44:59.359+0000] {logging_mixin.py:188} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=222) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-12-17T13:44:59.360+0000] {standard_task_runner.py:63} INFO - Started process 234 to run task
[2025-12-17T13:44:59.492+0000] {task_command.py:426} INFO - Running <TaskInstance: mfg_data_quality_monitoring_dag.dq_check_freshness_kpis scheduled__2025-12-16T05:30:00+00:00 [running]> on host 8717822a88d5
[2025-12-17T13:44:59.686+0000] {taskinstance.py:2644} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='data-eng' AIRFLOW_CTX_DAG_ID='mfg_data_quality_monitoring_dag' AIRFLOW_CTX_TASK_ID='dq_check_freshness_kpis' AIRFLOW_CTX_EXECUTION_DATE='2025-12-16T05:30:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-12-16T05:30:00+00:00'
[2025-12-17T13:44:59.691+0000] {taskinstance.py:430} INFO - ::endgroup::
[2025-12-17T13:44:59.721+0000] {connection.py:414} INFO - Snowflake Connector for Python Version: 3.12.0, Python Version: 3.12.2, Platform: Linux-6.6.87.2-microsoft-standard-WSL2-x86_64-with-glibc2.36
[2025-12-17T13:44:59.724+0000] {connection.py:1187} INFO - Connecting to GLOBAL Snowflake domain
[2025-12-17T13:44:59.725+0000] {connection.py:1268} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2025-12-17T13:45:01.643+0000] {cursor.py:1156} INFO - Number of results in first chunk: 1
[2025-12-17T13:45:01.645+0000] {connection.py:779} INFO - closed
[2025-12-17T13:45:01.868+0000] {connection.py:785} INFO - No async queries seem to be running, deleting session
[2025-12-17T13:45:02.156+0000] {python.py:237} INFO - Done. Returned value was: [CheckResult(check_name='freshness_mfg_plant_daily_kpis', severity='WARN', status='PASS', details={'max_calendar_date': '2026-01-08', 'today': '2025-12-17', 'delta_days': -22, 'threshold_days': 2})]
[2025-12-17T13:45:02.158+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2025-12-17T13:45:02.216+0000] {taskinstance.py:1205} INFO - Marking task as SUCCESS. dag_id=mfg_data_quality_monitoring_dag, task_id=dq_check_freshness_kpis, execution_date=20251216T053000, start_date=20251217T134459, end_date=20251217T134502
[2025-12-17T13:45:02.276+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2025-12-17T13:45:02.320+0000] {taskinstance.py:3482} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-12-17T13:45:02.327+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2025-12-17T18:25:31.502+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2025-12-17T18:25:31.547+0000] {taskinstance.py:2073} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: mfg_data_quality_monitoring_dag.dq_check_freshness_kpis scheduled__2025-12-16T05:30:00+00:00 [queued]>
[2025-12-17T18:25:31.557+0000] {taskinstance.py:2073} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: mfg_data_quality_monitoring_dag.dq_check_freshness_kpis scheduled__2025-12-16T05:30:00+00:00 [queued]>
[2025-12-17T18:25:31.558+0000] {taskinstance.py:2303} INFO - Starting attempt 1 of 2
[2025-12-17T18:25:31.576+0000] {taskinstance.py:2327} INFO - Executing <Task(PythonOperator): dq_check_freshness_kpis> on 2025-12-16 05:30:00+00:00
[2025-12-17T18:25:31.587+0000] {logging_mixin.py:188} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=2344) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-12-17T18:25:31.590+0000] {standard_task_runner.py:63} INFO - Started process 2352 to run task
[2025-12-17T18:25:31.589+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'mfg_data_quality_monitoring_dag', 'dq_check_freshness_kpis', 'scheduled__2025-12-16T05:30:00+00:00', '--job-id', '49', '--raw', '--subdir', 'DAGS_FOLDER/mfg_data_quality_monitoring_dag.py', '--cfg-path', '/tmp/tmpfy93588y']
[2025-12-17T18:25:31.594+0000] {standard_task_runner.py:91} INFO - Job 49: Subtask dq_check_freshness_kpis
[2025-12-17T18:25:31.686+0000] {task_command.py:426} INFO - Running <TaskInstance: mfg_data_quality_monitoring_dag.dq_check_freshness_kpis scheduled__2025-12-16T05:30:00+00:00 [running]> on host 8717822a88d5
[2025-12-17T18:25:31.819+0000] {taskinstance.py:2644} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='data-eng' AIRFLOW_CTX_DAG_ID='mfg_data_quality_monitoring_dag' AIRFLOW_CTX_TASK_ID='dq_check_freshness_kpis' AIRFLOW_CTX_EXECUTION_DATE='2025-12-16T05:30:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-12-16T05:30:00+00:00'
[2025-12-17T18:25:31.821+0000] {taskinstance.py:430} INFO - ::endgroup::
[2025-12-17T18:25:31.841+0000] {connection.py:414} INFO - Snowflake Connector for Python Version: 3.12.0, Python Version: 3.12.2, Platform: Linux-6.6.87.2-microsoft-standard-WSL2-x86_64-with-glibc2.36
[2025-12-17T18:25:31.843+0000] {connection.py:1187} INFO - Connecting to GLOBAL Snowflake domain
[2025-12-17T18:25:31.843+0000] {connection.py:1268} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2025-12-17T18:25:33.617+0000] {cursor.py:1156} INFO - Number of results in first chunk: 1
[2025-12-17T18:25:33.619+0000] {connection.py:779} INFO - closed
[2025-12-17T18:25:33.846+0000] {connection.py:785} INFO - No async queries seem to be running, deleting session
[2025-12-17T18:25:34.088+0000] {python.py:237} INFO - Done. Returned value was: [{'check_name': 'freshness_mfg_plant_daily_kpis', 'severity': 'WARN', 'status': 'PASS', 'details': {'table': 'MFG_ACCELERATOR.MARTS.MFG_PLANT_DAILY_KPIS', 'max_calendar_date': '2026-01-08', 'today': '2025-12-17', 'delta_days': -22, 'threshold_days': 2, 'marts_schema': 'MARTS'}}]
[2025-12-17T18:25:34.089+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2025-12-17T18:25:34.123+0000] {taskinstance.py:1205} INFO - Marking task as SUCCESS. dag_id=mfg_data_quality_monitoring_dag, task_id=dq_check_freshness_kpis, execution_date=20251216T053000, start_date=20251217T182531, end_date=20251217T182534
[2025-12-17T18:25:34.149+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2025-12-17T18:25:34.173+0000] {taskinstance.py:3482} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-12-17T18:25:34.178+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
