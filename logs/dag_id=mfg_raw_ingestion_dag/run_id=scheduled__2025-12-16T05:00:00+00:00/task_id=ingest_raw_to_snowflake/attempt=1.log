[2025-12-17T09:10:33.642+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2025-12-17T09:10:33.676+0000] {taskinstance.py:2073} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: mfg_raw_ingestion_dag.ingest_raw_to_snowflake scheduled__2025-12-16T05:00:00+00:00 [queued]>
[2025-12-17T09:10:33.684+0000] {taskinstance.py:2073} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: mfg_raw_ingestion_dag.ingest_raw_to_snowflake scheduled__2025-12-16T05:00:00+00:00 [queued]>
[2025-12-17T09:10:33.685+0000] {taskinstance.py:2303} INFO - Starting attempt 1 of 3
[2025-12-17T09:10:33.702+0000] {taskinstance.py:2327} INFO - Executing <Task(BashOperator): ingest_raw_to_snowflake> on 2025-12-16 05:00:00+00:00
[2025-12-17T09:10:33.709+0000] {logging_mixin.py:188} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=8078) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-12-17T09:10:33.710+0000] {standard_task_runner.py:63} INFO - Started process 8079 to run task
[2025-12-17T09:10:33.709+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'mfg_raw_ingestion_dag', 'ingest_raw_to_snowflake', 'scheduled__2025-12-16T05:00:00+00:00', '--job-id', '40', '--raw', '--subdir', 'DAGS_FOLDER/mfg_raw_ingestion_dag.py', '--cfg-path', '/tmp/tmp_zdn4c8g']
[2025-12-17T09:10:33.711+0000] {standard_task_runner.py:91} INFO - Job 40: Subtask ingest_raw_to_snowflake
[2025-12-17T09:10:33.769+0000] {task_command.py:426} INFO - Running <TaskInstance: mfg_raw_ingestion_dag.ingest_raw_to_snowflake scheduled__2025-12-16T05:00:00+00:00 [running]> on host f349782282f8
[2025-12-17T09:10:33.869+0000] {taskinstance.py:2644} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='data-eng' AIRFLOW_CTX_DAG_ID='mfg_raw_ingestion_dag' AIRFLOW_CTX_TASK_ID='ingest_raw_to_snowflake' AIRFLOW_CTX_EXECUTION_DATE='2025-12-16T05:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-12-16T05:00:00+00:00'
[2025-12-17T09:10:33.871+0000] {taskinstance.py:430} INFO - ::endgroup::
[2025-12-17T09:10:33.894+0000] {subprocess.py:63} INFO - Tmp dir root location: /tmp
[2025-12-17T09:10:33.896+0000] {subprocess.py:75} INFO - Running command: ['/usr/bin/bash', '-c', 'python /opt/***/ingestion/python/load_raw_to_snowflake.py']
[2025-12-17T09:10:33.905+0000] {subprocess.py:86} INFO - Output:
[2025-12-17T09:10:35.957+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 09:10:35 - Loaded environment from project-root .env
[2025-12-17T09:10:35.967+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 09:10:35 - Starting run-aware load. load_id=mfg_raw_ingestion_dag::scheduled__2025-12-16T05:00:00+00:00 dag_id=mfg_raw_ingestion_dag run_id=scheduled__2025-12-16T05:00:00+00:00 task_id=ingest_raw_to_snowflake
[2025-12-17T09:10:35.968+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 09:10:35 - Using data directory: /opt/***/data/raw/source_system
[2025-12-17T09:10:35.969+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 09:10:35 - Connecting to Snowflake...
[2025-12-17T09:10:40.980+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 09:10:40 - Read 500 rows from materials.csv
[2025-12-17T09:10:41.006+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 09:10:41 - Read 10,000 rows from batches.csv
[2025-12-17T09:10:41.037+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 09:10:41 - Read 10,000 rows from production_orders.csv
[2025-12-17T09:10:41.038+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 09:10:41 - [MATERIALS_RUN] Deleting previous slice for load_id (retry-safe)...
[2025-12-17T09:10:41.949+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 09:10:41 - [MATERIALS_RUN] Loading 500 rows from materials.csv ...
[2025-12-17T09:10:44.877+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 09:10:44 - [MATERIALS_RUN] write_pandas success=True rows_loaded=500 chunks=1
[2025-12-17T09:10:45.501+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 09:10:45 - [BATCHES_RUN] Deleting previous slice for load_id (retry-safe)...
[2025-12-17T09:10:45.949+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 09:10:45 - [BATCHES_RUN] Loading 10,000 rows from batches.csv ...
[2025-12-17T09:10:49.171+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 09:10:49 - [BATCHES_RUN] write_pandas success=True rows_loaded=10,000 chunks=1
[2025-12-17T09:10:49.706+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 09:10:49 - [PRODUCTION_ORDERS_RUN] Deleting previous slice for load_id (retry-safe)...
[2025-12-17T09:10:50.139+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 09:10:50 - [PRODUCTION_ORDERS_RUN] Loading 10,000 rows from production_orders.csv ...
[2025-12-17T09:10:53.338+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 09:10:53 - [PRODUCTION_ORDERS_RUN] write_pandas success=True rows_loaded=10,000 chunks=1
[2025-12-17T09:10:57.701+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 09:10:57 - Run-aware load committed successfully. load_id=mfg_raw_ingestion_dag::scheduled__2025-12-16T05:00:00+00:00
[2025-12-17T09:10:58.304+0000] {subprocess.py:97} INFO - Command exited with return code 0
[2025-12-17T09:10:58.305+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2025-12-17T09:10:58.340+0000] {taskinstance.py:1205} INFO - Marking task as SUCCESS. dag_id=mfg_raw_ingestion_dag, task_id=ingest_raw_to_snowflake, execution_date=20251216T050000, start_date=20251217T091033, end_date=20251217T091058
[2025-12-17T09:10:58.385+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2025-12-17T09:10:58.405+0000] {taskinstance.py:3482} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-12-17T09:10:58.410+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2025-12-17T09:31:23.651+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2025-12-17T09:31:23.782+0000] {taskinstance.py:2073} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: mfg_raw_ingestion_dag.ingest_raw_to_snowflake scheduled__2025-12-16T05:00:00+00:00 [queued]>
[2025-12-17T09:31:23.812+0000] {taskinstance.py:2073} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: mfg_raw_ingestion_dag.ingest_raw_to_snowflake scheduled__2025-12-16T05:00:00+00:00 [queued]>
[2025-12-17T09:31:23.813+0000] {taskinstance.py:2303} INFO - Starting attempt 1 of 3
[2025-12-17T09:31:23.834+0000] {taskinstance.py:2327} INFO - Executing <Task(BashOperator): ingest_raw_to_snowflake> on 2025-12-16 05:00:00+00:00
[2025-12-17T09:31:23.848+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'mfg_raw_ingestion_dag', 'ingest_raw_to_snowflake', 'scheduled__2025-12-16T05:00:00+00:00', '--job-id', '2', '--raw', '--subdir', 'DAGS_FOLDER/mfg_raw_ingestion_dag.py', '--cfg-path', '/tmp/tmpmqcm92rt']
[2025-12-17T09:31:23.856+0000] {standard_task_runner.py:91} INFO - Job 2: Subtask ingest_raw_to_snowflake
[2025-12-17T09:31:23.856+0000] {logging_mixin.py:188} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=333) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-12-17T09:31:23.857+0000] {standard_task_runner.py:63} INFO - Started process 334 to run task
[2025-12-17T09:31:23.943+0000] {task_command.py:426} INFO - Running <TaskInstance: mfg_raw_ingestion_dag.ingest_raw_to_snowflake scheduled__2025-12-16T05:00:00+00:00 [running]> on host 68b68f67a494
[2025-12-17T09:31:24.083+0000] {taskinstance.py:2644} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='data-eng' AIRFLOW_CTX_DAG_ID='mfg_raw_ingestion_dag' AIRFLOW_CTX_TASK_ID='ingest_raw_to_snowflake' AIRFLOW_CTX_EXECUTION_DATE='2025-12-16T05:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-12-16T05:00:00+00:00'
[2025-12-17T09:31:24.084+0000] {taskinstance.py:430} INFO - ::endgroup::
[2025-12-17T09:31:24.134+0000] {subprocess.py:63} INFO - Tmp dir root location: /tmp
[2025-12-17T09:31:24.136+0000] {subprocess.py:75} INFO - Running command: ['/usr/bin/bash', '-c', 'python /opt/***/ingestion/python/load_raw_to_snowflake.py']
[2025-12-17T09:31:24.151+0000] {subprocess.py:86} INFO - Output:
[2025-12-17T09:31:26.175+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 09:31:26 - No .env at project root; assuming env vars are injected (Docker/Airflow).
[2025-12-17T09:31:26.181+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 09:31:26 - Starting run-aware load. load_id=mfg_raw_ingestion_dag::scheduled__2025-12-16T05:00:00+00:00 dag_id=mfg_raw_ingestion_dag run_id=scheduled__2025-12-16T05:00:00+00:00 task_id=ingest_raw_to_snowflake
[2025-12-17T09:31:26.183+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 09:31:26 - Using data directory: /opt/***/data/raw/source_system
[2025-12-17T09:31:26.184+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 09:31:26 - Connecting to Snowflake...
[2025-12-17T09:31:30.965+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 09:31:30 - Read 500 rows from materials.csv
[2025-12-17T09:31:30.994+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 09:31:30 - Read 10,000 rows from batches.csv
[2025-12-17T09:31:31.023+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 09:31:31 - Read 10,000 rows from production_orders.csv
[2025-12-17T09:31:31.024+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 09:31:31 - [MATERIALS_RUN] Deleting previous slice for load_id (retry-safe)...
[2025-12-17T09:31:32.026+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 09:31:32 - [MATERIALS_RUN] Loading 500 rows from materials.csv ...
[2025-12-17T09:31:37.954+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 09:31:37 - [MATERIALS_RUN] write_pandas success=True rows_loaded=500 chunks=1
[2025-12-17T09:31:38.600+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 09:31:38 - [BATCHES_RUN] Deleting previous slice for load_id (retry-safe)...
[2025-12-17T09:31:39.261+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 09:31:39 - [BATCHES_RUN] Loading 10,000 rows from batches.csv ...
[2025-12-17T09:31:42.801+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 09:31:42 - [BATCHES_RUN] write_pandas success=True rows_loaded=10,000 chunks=1
[2025-12-17T09:31:43.359+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 09:31:43 - [PRODUCTION_ORDERS_RUN] Deleting previous slice for load_id (retry-safe)...
[2025-12-17T09:31:44.045+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 09:31:44 - [PRODUCTION_ORDERS_RUN] Loading 10,000 rows from production_orders.csv ...
[2025-12-17T09:31:47.726+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 09:31:47 - [PRODUCTION_ORDERS_RUN] write_pandas success=True rows_loaded=10,000 chunks=1
[2025-12-17T09:31:52.425+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 09:31:52 - Run-aware load committed successfully. load_id=mfg_raw_ingestion_dag::scheduled__2025-12-16T05:00:00+00:00
[2025-12-17T09:31:53.005+0000] {subprocess.py:97} INFO - Command exited with return code 0
[2025-12-17T09:31:53.006+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2025-12-17T09:31:53.041+0000] {taskinstance.py:1205} INFO - Marking task as SUCCESS. dag_id=mfg_raw_ingestion_dag, task_id=ingest_raw_to_snowflake, execution_date=20251216T050000, start_date=20251217T093123, end_date=20251217T093153
[2025-12-17T09:31:53.066+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2025-12-17T09:31:53.096+0000] {taskinstance.py:3482} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-12-17T09:31:53.101+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2025-12-17T10:09:22.847+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2025-12-17T10:09:22.893+0000] {taskinstance.py:2073} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: mfg_raw_ingestion_dag.ingest_raw_to_snowflake scheduled__2025-12-16T05:00:00+00:00 [queued]>
[2025-12-17T10:09:22.906+0000] {taskinstance.py:2073} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: mfg_raw_ingestion_dag.ingest_raw_to_snowflake scheduled__2025-12-16T05:00:00+00:00 [queued]>
[2025-12-17T10:09:22.906+0000] {taskinstance.py:2303} INFO - Starting attempt 1 of 3
[2025-12-17T10:09:22.924+0000] {taskinstance.py:2327} INFO - Executing <Task(BashOperator): ingest_raw_to_snowflake> on 2025-12-16 05:00:00+00:00
[2025-12-17T10:09:22.933+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'mfg_raw_ingestion_dag', 'ingest_raw_to_snowflake', 'scheduled__2025-12-16T05:00:00+00:00', '--job-id', '19', '--raw', '--subdir', 'DAGS_FOLDER/mfg_raw_ingestion_dag.py', '--cfg-path', '/tmp/tmpuxnacf0_']
[2025-12-17T10:09:22.937+0000] {logging_mixin.py:188} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=2149) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-12-17T10:09:22.939+0000] {standard_task_runner.py:91} INFO - Job 19: Subtask ingest_raw_to_snowflake
[2025-12-17T10:09:22.939+0000] {standard_task_runner.py:63} INFO - Started process 2150 to run task
[2025-12-17T10:09:23.023+0000] {task_command.py:426} INFO - Running <TaskInstance: mfg_raw_ingestion_dag.ingest_raw_to_snowflake scheduled__2025-12-16T05:00:00+00:00 [running]> on host 68b68f67a494
[2025-12-17T10:09:23.131+0000] {taskinstance.py:2644} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='data-eng' AIRFLOW_CTX_DAG_ID='mfg_raw_ingestion_dag' AIRFLOW_CTX_TASK_ID='ingest_raw_to_snowflake' AIRFLOW_CTX_EXECUTION_DATE='2025-12-16T05:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-12-16T05:00:00+00:00'
[2025-12-17T10:09:23.132+0000] {taskinstance.py:430} INFO - ::endgroup::
[2025-12-17T10:09:23.147+0000] {subprocess.py:63} INFO - Tmp dir root location: /tmp
[2025-12-17T10:09:23.148+0000] {subprocess.py:75} INFO - Running command: ['/usr/bin/bash', '-c', 'python /opt/***/ingestion/python/load_raw_to_snowflake.py']
[2025-12-17T10:09:23.157+0000] {subprocess.py:86} INFO - Output:
[2025-12-17T10:09:24.644+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 10:09:24 - No .env at project root; assuming env vars are injected (Docker/Airflow).
[2025-12-17T10:09:24.648+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 10:09:24 - Starting run-aware load. load_id=mfg_raw_ingestion_dag::scheduled__2025-12-16T05:00:00+00:00 dag_id=mfg_raw_ingestion_dag run_id=scheduled__2025-12-16T05:00:00+00:00 task_id=ingest_raw_to_snowflake
[2025-12-17T10:09:24.649+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 10:09:24 - Using data directory: /opt/***/data/raw/source_system
[2025-12-17T10:09:24.649+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 10:09:24 - Connecting to Snowflake...
[2025-12-17T10:09:29.410+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 10:09:29 - Read 500 rows from materials.csv
[2025-12-17T10:09:29.439+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 10:09:29 - Read 10,000 rows from batches.csv
[2025-12-17T10:09:29.471+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 10:09:29 - Read 10,000 rows from production_orders.csv
[2025-12-17T10:09:29.471+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 10:09:29 - [MATERIALS_RUN] Deleting previous slice for load_id (retry-safe)...
[2025-12-17T10:09:30.625+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 10:09:30 - [MATERIALS_RUN] Loading 500 rows from materials.csv ...
[2025-12-17T10:09:33.605+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 10:09:33 - [MATERIALS_RUN] write_pandas success=True rows_loaded=500 chunks=1
[2025-12-17T10:09:34.494+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 10:09:34 - [BATCHES_RUN] Deleting previous slice for load_id (retry-safe)...
[2025-12-17T10:09:35.337+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 10:09:35 - [BATCHES_RUN] Loading 10,000 rows from batches.csv ...
[2025-12-17T10:09:38.560+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 10:09:38 - [BATCHES_RUN] write_pandas success=True rows_loaded=10,000 chunks=1
[2025-12-17T10:09:39.159+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 10:09:39 - [PRODUCTION_ORDERS_RUN] Deleting previous slice for load_id (retry-safe)...
[2025-12-17T10:09:40.111+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 10:09:40 - [PRODUCTION_ORDERS_RUN] Loading 10,000 rows from production_orders.csv ...
[2025-12-17T10:09:43.341+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 10:09:43 - [PRODUCTION_ORDERS_RUN] write_pandas success=True rows_loaded=10,000 chunks=1
[2025-12-17T10:09:47.874+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 10:09:47 - Run-aware load committed successfully. load_id=mfg_raw_ingestion_dag::scheduled__2025-12-16T05:00:00+00:00
[2025-12-17T10:09:48.459+0000] {subprocess.py:97} INFO - Command exited with return code 0
[2025-12-17T10:09:48.460+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2025-12-17T10:09:48.495+0000] {taskinstance.py:1205} INFO - Marking task as SUCCESS. dag_id=mfg_raw_ingestion_dag, task_id=ingest_raw_to_snowflake, execution_date=20251216T050000, start_date=20251217T100922, end_date=20251217T100948
[2025-12-17T10:09:48.516+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2025-12-17T10:09:48.547+0000] {taskinstance.py:3482} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-12-17T10:09:48.552+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2025-12-17T10:28:15.355+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2025-12-17T10:28:15.396+0000] {taskinstance.py:2073} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: mfg_raw_ingestion_dag.ingest_raw_to_snowflake scheduled__2025-12-16T05:00:00+00:00 [queued]>
[2025-12-17T10:28:15.405+0000] {taskinstance.py:2073} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: mfg_raw_ingestion_dag.ingest_raw_to_snowflake scheduled__2025-12-16T05:00:00+00:00 [queued]>
[2025-12-17T10:28:15.405+0000] {taskinstance.py:2303} INFO - Starting attempt 1 of 3
[2025-12-17T10:28:15.421+0000] {taskinstance.py:2327} INFO - Executing <Task(BashOperator): ingest_raw_to_snowflake> on 2025-12-16 05:00:00+00:00
[2025-12-17T10:28:15.430+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'mfg_raw_ingestion_dag', 'ingest_raw_to_snowflake', 'scheduled__2025-12-16T05:00:00+00:00', '--job-id', '30', '--raw', '--subdir', 'DAGS_FOLDER/mfg_raw_ingestion_dag.py', '--cfg-path', '/tmp/tmplecpql_u']
[2025-12-17T10:28:15.433+0000] {standard_task_runner.py:91} INFO - Job 30: Subtask ingest_raw_to_snowflake
[2025-12-17T10:28:15.433+0000] {logging_mixin.py:188} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=267) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-12-17T10:28:15.434+0000] {standard_task_runner.py:63} INFO - Started process 268 to run task
[2025-12-17T10:28:15.505+0000] {task_command.py:426} INFO - Running <TaskInstance: mfg_raw_ingestion_dag.ingest_raw_to_snowflake scheduled__2025-12-16T05:00:00+00:00 [running]> on host a197bc4252bf
[2025-12-17T10:28:15.619+0000] {taskinstance.py:2644} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='data-eng' AIRFLOW_CTX_DAG_ID='mfg_raw_ingestion_dag' AIRFLOW_CTX_TASK_ID='ingest_raw_to_snowflake' AIRFLOW_CTX_EXECUTION_DATE='2025-12-16T05:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-12-16T05:00:00+00:00'
[2025-12-17T10:28:15.621+0000] {taskinstance.py:430} INFO - ::endgroup::
[2025-12-17T10:28:15.640+0000] {subprocess.py:63} INFO - Tmp dir root location: /tmp
[2025-12-17T10:28:15.641+0000] {subprocess.py:75} INFO - Running command: ['/usr/bin/bash', '-c', 'python /opt/***/ingestion/python/load_raw_to_snowflake.py']
[2025-12-17T10:28:15.650+0000] {subprocess.py:86} INFO - Output:
[2025-12-17T10:28:17.455+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 10:28:17 - No .env at project root; assuming env vars are injected (Docker/Airflow).
[2025-12-17T10:28:17.461+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 10:28:17 - Starting run-aware load. load_id=mfg_raw_ingestion_dag::scheduled__2025-12-16T05:00:00+00:00 dag_id=mfg_raw_ingestion_dag run_id=scheduled__2025-12-16T05:00:00+00:00 task_id=ingest_raw_to_snowflake
[2025-12-17T10:28:17.462+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 10:28:17 - Using data directory: /opt/***/data/raw/source_system
[2025-12-17T10:28:17.462+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 10:28:17 - Connecting to Snowflake...
[2025-12-17T10:28:21.751+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 10:28:21 - Read 500 rows from materials.csv
[2025-12-17T10:28:21.774+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 10:28:21 - Read 10,000 rows from batches.csv
[2025-12-17T10:28:21.805+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 10:28:21 - Read 10,000 rows from production_orders.csv
[2025-12-17T10:28:21.806+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 10:28:21 - [MATERIALS_RUN] Deleting previous slice for load_id (retry-safe)...
[2025-12-17T10:28:22.419+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 10:28:22 - [MATERIALS_RUN] Loading 500 rows from materials.csv ...
[2025-12-17T10:28:25.373+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 10:28:25 - [MATERIALS_RUN] write_pandas success=True rows_loaded=500 chunks=1
[2025-12-17T10:28:25.880+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 10:28:25 - [BATCHES_RUN] Deleting previous slice for load_id (retry-safe)...
[2025-12-17T10:28:26.676+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 10:28:26 - [BATCHES_RUN] Loading 10,000 rows from batches.csv ...
[2025-12-17T10:28:29.745+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 10:28:29 - [BATCHES_RUN] write_pandas success=True rows_loaded=10,000 chunks=1
[2025-12-17T10:28:30.475+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 10:28:30 - [PRODUCTION_ORDERS_RUN] Deleting previous slice for load_id (retry-safe)...
[2025-12-17T10:28:31.190+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 10:28:31 - [PRODUCTION_ORDERS_RUN] Loading 10,000 rows from production_orders.csv ...
[2025-12-17T10:28:34.360+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 10:28:34 - [PRODUCTION_ORDERS_RUN] write_pandas success=True rows_loaded=10,000 chunks=1
[2025-12-17T10:28:38.688+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 10:28:38 - Run-aware load committed successfully. load_id=mfg_raw_ingestion_dag::scheduled__2025-12-16T05:00:00+00:00
[2025-12-17T10:28:39.343+0000] {subprocess.py:97} INFO - Command exited with return code 0
[2025-12-17T10:28:39.344+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2025-12-17T10:28:39.383+0000] {taskinstance.py:1205} INFO - Marking task as SUCCESS. dag_id=mfg_raw_ingestion_dag, task_id=ingest_raw_to_snowflake, execution_date=20251216T050000, start_date=20251217T102815, end_date=20251217T102839
[2025-12-17T10:28:39.420+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2025-12-17T10:28:39.453+0000] {taskinstance.py:3482} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-12-17T10:28:39.458+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2025-12-17T10:57:25.107+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2025-12-17T10:57:25.228+0000] {taskinstance.py:2073} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: mfg_raw_ingestion_dag.ingest_raw_to_snowflake scheduled__2025-12-16T05:00:00+00:00 [queued]>
[2025-12-17T10:57:25.240+0000] {taskinstance.py:2073} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: mfg_raw_ingestion_dag.ingest_raw_to_snowflake scheduled__2025-12-16T05:00:00+00:00 [queued]>
[2025-12-17T10:57:25.240+0000] {taskinstance.py:2303} INFO - Starting attempt 1 of 3
[2025-12-17T10:57:25.258+0000] {taskinstance.py:2327} INFO - Executing <Task(BashOperator): ingest_raw_to_snowflake> on 2025-12-16 05:00:00+00:00
[2025-12-17T10:57:25.267+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'mfg_raw_ingestion_dag', 'ingest_raw_to_snowflake', 'scheduled__2025-12-16T05:00:00+00:00', '--job-id', '4', '--raw', '--subdir', 'DAGS_FOLDER/mfg_raw_ingestion_dag.py', '--cfg-path', '/tmp/tmpekb4xtoz']
[2025-12-17T10:57:25.274+0000] {standard_task_runner.py:91} INFO - Job 4: Subtask ingest_raw_to_snowflake
[2025-12-17T10:57:25.275+0000] {logging_mixin.py:188} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=532) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-12-17T10:57:25.276+0000] {standard_task_runner.py:63} INFO - Started process 533 to run task
[2025-12-17T10:57:25.362+0000] {task_command.py:426} INFO - Running <TaskInstance: mfg_raw_ingestion_dag.ingest_raw_to_snowflake scheduled__2025-12-16T05:00:00+00:00 [running]> on host ada33a2b5ec7
[2025-12-17T10:57:25.491+0000] {taskinstance.py:2644} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='data-eng' AIRFLOW_CTX_DAG_ID='mfg_raw_ingestion_dag' AIRFLOW_CTX_TASK_ID='ingest_raw_to_snowflake' AIRFLOW_CTX_EXECUTION_DATE='2025-12-16T05:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-12-16T05:00:00+00:00'
[2025-12-17T10:57:25.492+0000] {taskinstance.py:430} INFO - ::endgroup::
[2025-12-17T10:57:25.530+0000] {subprocess.py:63} INFO - Tmp dir root location: /tmp
[2025-12-17T10:57:25.532+0000] {subprocess.py:75} INFO - Running command: ['/usr/bin/bash', '-c', 'python /opt/***/ingestion/python/load_raw_to_snowflake.py']
[2025-12-17T10:57:25.541+0000] {subprocess.py:86} INFO - Output:
[2025-12-17T10:57:27.268+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 10:57:27 - No .env at project root; assuming env vars are injected (Docker/Airflow).
[2025-12-17T10:57:27.273+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 10:57:27 - Starting run-aware load. load_id=mfg_raw_ingestion_dag::scheduled__2025-12-16T05:00:00+00:00 dag_id=mfg_raw_ingestion_dag run_id=scheduled__2025-12-16T05:00:00+00:00 task_id=ingest_raw_to_snowflake
[2025-12-17T10:57:27.273+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 10:57:27 - Using data directory: /opt/***/data/raw/source_system
[2025-12-17T10:57:27.274+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 10:57:27 - Connecting to Snowflake...
[2025-12-17T10:57:31.481+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 10:57:31 - Read 500 rows from materials.csv
[2025-12-17T10:57:31.523+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 10:57:31 - Read 10,000 rows from batches.csv
[2025-12-17T10:57:31.568+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 10:57:31 - Read 10,000 rows from production_orders.csv
[2025-12-17T10:57:31.569+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 10:57:31 - [MATERIALS_RUN] Deleting previous slice for load_id (retry-safe)...
[2025-12-17T10:57:32.083+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 10:57:32 - [MATERIALS_RUN] Loading 500 rows from materials.csv ...
[2025-12-17T10:57:36.098+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 10:57:36 - [MATERIALS_RUN] write_pandas success=True rows_loaded=500 chunks=1
[2025-12-17T10:57:36.610+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 10:57:36 - [BATCHES_RUN] Deleting previous slice for load_id (retry-safe)...
[2025-12-17T10:57:37.359+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 10:57:37 - [BATCHES_RUN] Loading 10,000 rows from batches.csv ...
[2025-12-17T10:57:40.661+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 10:57:40 - [BATCHES_RUN] write_pandas success=True rows_loaded=10,000 chunks=1
[2025-12-17T10:57:41.194+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 10:57:41 - [PRODUCTION_ORDERS_RUN] Deleting previous slice for load_id (retry-safe)...
[2025-12-17T10:57:42.078+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 10:57:42 - [PRODUCTION_ORDERS_RUN] Loading 10,000 rows from production_orders.csv ...
[2025-12-17T10:57:45.543+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 10:57:45 - [PRODUCTION_ORDERS_RUN] write_pandas success=True rows_loaded=10,000 chunks=1
[2025-12-17T10:57:50.046+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 10:57:50 - Run-aware load committed successfully. load_id=mfg_raw_ingestion_dag::scheduled__2025-12-16T05:00:00+00:00
[2025-12-17T10:57:50.630+0000] {subprocess.py:97} INFO - Command exited with return code 0
[2025-12-17T10:57:50.631+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2025-12-17T10:57:50.665+0000] {taskinstance.py:1205} INFO - Marking task as SUCCESS. dag_id=mfg_raw_ingestion_dag, task_id=ingest_raw_to_snowflake, execution_date=20251216T050000, start_date=20251217T105725, end_date=20251217T105750
[2025-12-17T10:57:50.694+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2025-12-17T10:57:50.719+0000] {taskinstance.py:3482} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-12-17T10:57:50.724+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2025-12-17T12:56:31.955+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2025-12-17T12:56:32.074+0000] {taskinstance.py:2073} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: mfg_raw_ingestion_dag.ingest_raw_to_snowflake scheduled__2025-12-16T05:00:00+00:00 [queued]>
[2025-12-17T12:56:32.093+0000] {taskinstance.py:2073} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: mfg_raw_ingestion_dag.ingest_raw_to_snowflake scheduled__2025-12-16T05:00:00+00:00 [queued]>
[2025-12-17T12:56:32.094+0000] {taskinstance.py:2303} INFO - Starting attempt 1 of 3
[2025-12-17T12:56:32.113+0000] {taskinstance.py:2327} INFO - Executing <Task(BashOperator): ingest_raw_to_snowflake> on 2025-12-16 05:00:00+00:00
[2025-12-17T12:56:32.121+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'mfg_raw_ingestion_dag', 'ingest_raw_to_snowflake', 'scheduled__2025-12-16T05:00:00+00:00', '--job-id', '2', '--raw', '--subdir', 'DAGS_FOLDER/mfg_raw_ingestion_dag.py', '--cfg-path', '/tmp/tmp3hsjo3e_']
[2025-12-17T12:56:32.127+0000] {standard_task_runner.py:91} INFO - Job 2: Subtask ingest_raw_to_snowflake
[2025-12-17T12:56:32.127+0000] {logging_mixin.py:188} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=208) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-12-17T12:56:32.129+0000] {standard_task_runner.py:63} INFO - Started process 209 to run task
[2025-12-17T12:56:32.222+0000] {task_command.py:426} INFO - Running <TaskInstance: mfg_raw_ingestion_dag.ingest_raw_to_snowflake scheduled__2025-12-16T05:00:00+00:00 [running]> on host 84fc30c39b31
[2025-12-17T12:56:32.354+0000] {taskinstance.py:2644} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='data-eng' AIRFLOW_CTX_DAG_ID='mfg_raw_ingestion_dag' AIRFLOW_CTX_TASK_ID='ingest_raw_to_snowflake' AIRFLOW_CTX_EXECUTION_DATE='2025-12-16T05:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-12-16T05:00:00+00:00'
[2025-12-17T12:56:32.356+0000] {taskinstance.py:430} INFO - ::endgroup::
[2025-12-17T12:56:32.392+0000] {subprocess.py:63} INFO - Tmp dir root location: /tmp
[2025-12-17T12:56:32.393+0000] {subprocess.py:75} INFO - Running command: ['/usr/bin/bash', '-c', 'python /opt/***/ingestion/python/load_raw_to_snowflake.py']
[2025-12-17T12:56:32.402+0000] {subprocess.py:86} INFO - Output:
[2025-12-17T12:56:34.092+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 12:56:34 - No .env at project root; assuming env vars are injected (Docker/Airflow).
[2025-12-17T12:56:34.096+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 12:56:34 - Starting run-aware load. load_id=mfg_raw_ingestion_dag::scheduled__2025-12-16T05:00:00+00:00 dag_id=mfg_raw_ingestion_dag run_id=scheduled__2025-12-16T05:00:00+00:00 task_id=ingest_raw_to_snowflake
[2025-12-17T12:56:34.096+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 12:56:34 - Using data directory: /opt/***/data/raw/source_system
[2025-12-17T12:56:34.097+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 12:56:34 - Connecting to Snowflake...
[2025-12-17T12:56:39.208+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 12:56:39 - Read 500 rows from materials.csv
[2025-12-17T12:56:39.234+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 12:56:39 - Read 10,000 rows from batches.csv
[2025-12-17T12:56:39.267+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 12:56:39 - Read 10,000 rows from production_orders.csv
[2025-12-17T12:56:39.268+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 12:56:39 - [MATERIALS_RUN] Deleting previous slice for load_id (retry-safe)...
[2025-12-17T12:56:40.807+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 12:56:40 - [MATERIALS_RUN] Loading 500 rows from materials.csv ...
[2025-12-17T12:56:45.033+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 12:56:45 - [MATERIALS_RUN] write_pandas success=True rows_loaded=500 chunks=1
[2025-12-17T12:56:45.707+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 12:56:45 - [BATCHES_RUN] Deleting previous slice for load_id (retry-safe)...
[2025-12-17T12:56:46.868+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 12:56:46 - [BATCHES_RUN] Loading 10,000 rows from batches.csv ...
[2025-12-17T12:56:50.388+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 12:56:50 - [BATCHES_RUN] write_pandas success=True rows_loaded=10,000 chunks=1
[2025-12-17T12:56:51.073+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 12:56:51 - [PRODUCTION_ORDERS_RUN] Deleting previous slice for load_id (retry-safe)...
[2025-12-17T12:56:52.141+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 12:56:52 - [PRODUCTION_ORDERS_RUN] Loading 10,000 rows from production_orders.csv ...
[2025-12-17T12:56:56.112+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 12:56:56 - [PRODUCTION_ORDERS_RUN] write_pandas success=True rows_loaded=10,000 chunks=1
[2025-12-17T12:57:01.254+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 12:57:01 - Run-aware load committed successfully. load_id=mfg_raw_ingestion_dag::scheduled__2025-12-16T05:00:00+00:00
[2025-12-17T12:57:01.825+0000] {subprocess.py:97} INFO - Command exited with return code 0
[2025-12-17T12:57:01.826+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2025-12-17T12:57:01.860+0000] {taskinstance.py:1205} INFO - Marking task as SUCCESS. dag_id=mfg_raw_ingestion_dag, task_id=ingest_raw_to_snowflake, execution_date=20251216T050000, start_date=20251217T125632, end_date=20251217T125701
[2025-12-17T12:57:01.896+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2025-12-17T12:57:01.922+0000] {taskinstance.py:3482} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-12-17T12:57:01.927+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2025-12-17T13:11:22.150+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2025-12-17T13:11:22.189+0000] {taskinstance.py:2073} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: mfg_raw_ingestion_dag.ingest_raw_to_snowflake scheduled__2025-12-16T05:00:00+00:00 [queued]>
[2025-12-17T13:11:22.198+0000] {taskinstance.py:2073} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: mfg_raw_ingestion_dag.ingest_raw_to_snowflake scheduled__2025-12-16T05:00:00+00:00 [queued]>
[2025-12-17T13:11:22.199+0000] {taskinstance.py:2303} INFO - Starting attempt 1 of 3
[2025-12-17T13:11:22.214+0000] {taskinstance.py:2327} INFO - Executing <Task(BashOperator): ingest_raw_to_snowflake> on 2025-12-16 05:00:00+00:00
[2025-12-17T13:11:22.222+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'mfg_raw_ingestion_dag', 'ingest_raw_to_snowflake', 'scheduled__2025-12-16T05:00:00+00:00', '--job-id', '28', '--raw', '--subdir', 'DAGS_FOLDER/mfg_raw_ingestion_dag.py', '--cfg-path', '/tmp/tmpgug51huh']
[2025-12-17T13:11:22.226+0000] {standard_task_runner.py:91} INFO - Job 28: Subtask ingest_raw_to_snowflake
[2025-12-17T13:11:22.226+0000] {logging_mixin.py:188} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=1375) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-12-17T13:11:22.227+0000] {standard_task_runner.py:63} INFO - Started process 1378 to run task
[2025-12-17T13:11:22.294+0000] {task_command.py:426} INFO - Running <TaskInstance: mfg_raw_ingestion_dag.ingest_raw_to_snowflake scheduled__2025-12-16T05:00:00+00:00 [running]> on host 84fc30c39b31
[2025-12-17T13:11:22.394+0000] {taskinstance.py:2644} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='data-eng' AIRFLOW_CTX_DAG_ID='mfg_raw_ingestion_dag' AIRFLOW_CTX_TASK_ID='ingest_raw_to_snowflake' AIRFLOW_CTX_EXECUTION_DATE='2025-12-16T05:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-12-16T05:00:00+00:00'
[2025-12-17T13:11:22.395+0000] {taskinstance.py:430} INFO - ::endgroup::
[2025-12-17T13:11:22.411+0000] {subprocess.py:63} INFO - Tmp dir root location: /tmp
[2025-12-17T13:11:22.412+0000] {subprocess.py:75} INFO - Running command: ['/usr/bin/bash', '-c', 'python /opt/***/ingestion/python/load_raw_to_snowflake.py']
[2025-12-17T13:11:22.421+0000] {subprocess.py:86} INFO - Output:
[2025-12-17T13:11:24.110+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 13:11:24 - No .env at project root; assuming env vars are injected (Docker/Airflow).
[2025-12-17T13:11:24.114+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 13:11:24 - Starting run-aware load. load_id=mfg_raw_ingestion_dag::scheduled__2025-12-16T05:00:00+00:00 dag_id=mfg_raw_ingestion_dag run_id=scheduled__2025-12-16T05:00:00+00:00 task_id=ingest_raw_to_snowflake
[2025-12-17T13:11:24.114+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 13:11:24 - Using data directory: /opt/***/data/raw/source_system
[2025-12-17T13:11:24.115+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 13:11:24 - Connecting to Snowflake...
[2025-12-17T13:11:28.478+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 13:11:28 - Read 500 rows from materials.csv
[2025-12-17T13:11:28.504+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 13:11:28 - Read 10,000 rows from batches.csv
[2025-12-17T13:11:28.534+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 13:11:28 - Read 10,000 rows from production_orders.csv
[2025-12-17T13:11:28.534+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 13:11:28 - [MATERIALS_RUN] Deleting previous slice for load_id (retry-safe)...
[2025-12-17T13:11:29.663+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 13:11:29 - [MATERIALS_RUN] Loading 500 rows from materials.csv ...
[2025-12-17T13:11:32.859+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 13:11:32 - [MATERIALS_RUN] write_pandas success=True rows_loaded=500 chunks=1
[2025-12-17T13:11:33.387+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 13:11:33 - [BATCHES_RUN] Deleting previous slice for load_id (retry-safe)...
[2025-12-17T13:11:34.085+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 13:11:34 - [BATCHES_RUN] Loading 10,000 rows from batches.csv ...
[2025-12-17T13:11:37.424+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 13:11:37 - [BATCHES_RUN] write_pandas success=True rows_loaded=10,000 chunks=1
[2025-12-17T13:11:37.970+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 13:11:37 - [PRODUCTION_ORDERS_RUN] Deleting previous slice for load_id (retry-safe)...
[2025-12-17T13:11:38.893+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 13:11:38 - [PRODUCTION_ORDERS_RUN] Loading 10,000 rows from production_orders.csv ...
[2025-12-17T13:11:42.470+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 13:11:42 - [PRODUCTION_ORDERS_RUN] write_pandas success=True rows_loaded=10,000 chunks=1
[2025-12-17T13:11:47.480+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 13:11:47 - Run-aware load committed successfully. load_id=mfg_raw_ingestion_dag::scheduled__2025-12-16T05:00:00+00:00
[2025-12-17T13:11:48.043+0000] {subprocess.py:97} INFO - Command exited with return code 0
[2025-12-17T13:11:48.044+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2025-12-17T13:11:48.078+0000] {taskinstance.py:1205} INFO - Marking task as SUCCESS. dag_id=mfg_raw_ingestion_dag, task_id=ingest_raw_to_snowflake, execution_date=20251216T050000, start_date=20251217T131122, end_date=20251217T131148
[2025-12-17T13:11:48.110+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2025-12-17T13:11:48.137+0000] {taskinstance.py:3482} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-12-17T13:11:48.141+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2025-12-17T13:44:52.101+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2025-12-17T13:44:52.150+0000] {taskinstance.py:2073} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: mfg_raw_ingestion_dag.ingest_raw_to_snowflake scheduled__2025-12-16T05:00:00+00:00 [queued]>
[2025-12-17T13:44:52.163+0000] {taskinstance.py:2073} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: mfg_raw_ingestion_dag.ingest_raw_to_snowflake scheduled__2025-12-16T05:00:00+00:00 [queued]>
[2025-12-17T13:44:52.164+0000] {taskinstance.py:2303} INFO - Starting attempt 1 of 3
[2025-12-17T13:44:52.183+0000] {taskinstance.py:2327} INFO - Executing <Task(BashOperator): ingest_raw_to_snowflake> on 2025-12-16 05:00:00+00:00
[2025-12-17T13:44:52.192+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'mfg_raw_ingestion_dag', 'ingest_raw_to_snowflake', 'scheduled__2025-12-16T05:00:00+00:00', '--job-id', '2', '--raw', '--subdir', 'DAGS_FOLDER/mfg_raw_ingestion_dag.py', '--cfg-path', '/tmp/tmpxve5u_xl']
[2025-12-17T13:44:52.198+0000] {standard_task_runner.py:91} INFO - Job 2: Subtask ingest_raw_to_snowflake
[2025-12-17T13:44:52.200+0000] {logging_mixin.py:188} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=186) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-12-17T13:44:52.202+0000] {standard_task_runner.py:63} INFO - Started process 187 to run task
[2025-12-17T13:44:52.300+0000] {task_command.py:426} INFO - Running <TaskInstance: mfg_raw_ingestion_dag.ingest_raw_to_snowflake scheduled__2025-12-16T05:00:00+00:00 [running]> on host 8717822a88d5
[2025-12-17T13:44:52.434+0000] {taskinstance.py:2644} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='data-eng' AIRFLOW_CTX_DAG_ID='mfg_raw_ingestion_dag' AIRFLOW_CTX_TASK_ID='ingest_raw_to_snowflake' AIRFLOW_CTX_EXECUTION_DATE='2025-12-16T05:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-12-16T05:00:00+00:00'
[2025-12-17T13:44:52.435+0000] {taskinstance.py:430} INFO - ::endgroup::
[2025-12-17T13:44:52.470+0000] {subprocess.py:63} INFO - Tmp dir root location: /tmp
[2025-12-17T13:44:52.471+0000] {subprocess.py:75} INFO - Running command: ['/usr/bin/bash', '-c', 'python /opt/***/ingestion/python/load_raw_to_snowflake.py']
[2025-12-17T13:44:52.482+0000] {subprocess.py:86} INFO - Output:
[2025-12-17T13:44:55.057+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 13:44:55 - No .env at project root; assuming env vars are injected (Docker/Airflow).
[2025-12-17T13:44:55.063+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 13:44:55 - Starting run-aware load. load_id=mfg_raw_ingestion_dag::scheduled__2025-12-16T05:00:00+00:00 dag_id=mfg_raw_ingestion_dag run_id=scheduled__2025-12-16T05:00:00+00:00 task_id=ingest_raw_to_snowflake
[2025-12-17T13:44:55.065+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 13:44:55 - Using data directory: /opt/***/data/raw/source_system
[2025-12-17T13:44:55.066+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 13:44:55 - Connecting to Snowflake...
[2025-12-17T13:45:01.707+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 13:45:01 - Read 500 rows from materials.csv
[2025-12-17T13:45:01.769+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 13:45:01 - Read 10,000 rows from batches.csv
[2025-12-17T13:45:01.836+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 13:45:01 - Read 10,000 rows from production_orders.csv
[2025-12-17T13:45:01.839+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 13:45:01 - [MATERIALS_RUN] Deleting previous slice for load_id (retry-safe)...
[2025-12-17T13:45:02.512+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 13:45:02 - [MATERIALS_RUN] Loading 500 rows from materials.csv ...
[2025-12-17T13:45:08.677+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 13:45:08 - [MATERIALS_RUN] write_pandas success=True rows_loaded=500 chunks=1
[2025-12-17T13:45:09.181+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 13:45:09 - [BATCHES_RUN] Deleting previous slice for load_id (retry-safe)...
[2025-12-17T13:45:09.800+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 13:45:09 - [BATCHES_RUN] Loading 10,000 rows from batches.csv ...
[2025-12-17T13:45:12.700+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 13:45:12 - [BATCHES_RUN] write_pandas success=True rows_loaded=10,000 chunks=1
[2025-12-17T13:45:13.245+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 13:45:13 - [PRODUCTION_ORDERS_RUN] Deleting previous slice for load_id (retry-safe)...
[2025-12-17T13:45:13.884+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 13:45:13 - [PRODUCTION_ORDERS_RUN] Loading 10,000 rows from production_orders.csv ...
[2025-12-17T13:45:17.041+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 13:45:17 - [PRODUCTION_ORDERS_RUN] write_pandas success=True rows_loaded=10,000 chunks=1
[2025-12-17T13:45:22.169+0000] {subprocess.py:93} INFO - [INFO] 2025-12-17 13:45:22 - Run-aware load committed successfully. load_id=mfg_raw_ingestion_dag::scheduled__2025-12-16T05:00:00+00:00
[2025-12-17T13:45:22.717+0000] {subprocess.py:97} INFO - Command exited with return code 0
[2025-12-17T13:45:22.718+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2025-12-17T13:45:22.751+0000] {taskinstance.py:1205} INFO - Marking task as SUCCESS. dag_id=mfg_raw_ingestion_dag, task_id=ingest_raw_to_snowflake, execution_date=20251216T050000, start_date=20251217T134452, end_date=20251217T134522
[2025-12-17T13:45:22.772+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2025-12-17T13:45:22.799+0000] {taskinstance.py:3482} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-12-17T13:45:22.804+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
